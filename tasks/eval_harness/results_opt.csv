task,metric,value,err,version
arc_challenge,acc,0.4035836177474403,0.014337158914268447,0
arc_challenge,acc_norm,0.44112627986348124,0.014509747749064664,0
arc_easy,acc,0.7483164983164983,0.008905088235948768,0
arc_easy,acc_norm,0.7117003367003367,0.009294774252029625,0
boolq,acc,0.7828746177370031,0.007210974239098775,1
copa,acc,0.88,0.03265986323710906,0
hellaswag,acc,0.5932085241983669,0.0049023140557255965,0
hellaswag,acc_norm,0.7848038239394542,0.004101184870964189,0
lambada,acc,0.746749466330293,0.006058634002437447,0
logiqa,acc,0.23963133640552994,0.016742766935101423,0
logiqa,acc_norm,0.2995391705069124,0.01796644118858794,0
mathqa,acc,0.2629815745393635,0.008059394672720415,0
mathqa,acc_norm,0.2639865996649916,0.008069272694433298,0
mc_taco,f1,0.5016636994040179,,0
mrpc,acc,0.47549019607843135,0.024754284840506468,0
mrpc,f1,0.5,0.029682593695340015,0
multirc,acc,0.014690451206715634,0.003899289130707259,-1
openbookqa,acc,0.34,0.021206117013673066,0
openbookqa,acc_norm,0.454,0.02228814759117695,0
piqa,acc,0.7965179542981502,0.009393041784049923,0
piqa,acc_norm,0.8101196953210011,0.009150819250948716,0
prost,acc,0.305401366353544,0.0033649266480613007,0
prost,acc_norm,0.306468830059778,0.003368211069781756,0
pubmedqa,acc,0.704,0.014442734941575025,0
qnli,acc,0.538348892549881,0.006745482267535849,0
qqp,acc,0.479248083106604,0.002484557952829062,0
qqp,f1,0.43518617877454663,0.003218904618480992,0
race,acc,0.4076555023923445,0.015208402023513217,1
rte,acc,0.5992779783393501,0.029497229237163143,0
sciq,acc,0.942,0.007395315455792963,0
sciq,acc_norm,0.919,0.008632121032139988,0
sst,acc,0.6479357798165137,0.016183328477435827,0
triviaqa,acc,0.3497745955979846,0.004483904973085589,0
webqs,acc,0.14566929133858267,0.007827841991316377,0
wic,acc,0.5141065830721003,0.01980283522800584,0
winogrande,acc,0.728492501973165,0.012499326254893129,0
wnli,acc,0.5492957746478874,0.05947027187738001,1
wsc,acc,0.5288461538461539,0.04918440626354964,0
